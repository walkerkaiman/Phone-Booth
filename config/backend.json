{
	"llm": {
		"engine": "llama_cpp",
		"model_path": "/models/llama3.1-8b.Q4_K_M.gguf",
		"context_length": 2048,
		"temperature": 0.8,
		"top_p": 0.9,
		"max_tokens": 180
	},
	"sessions": {
		"ttl_seconds": 600,
		"history_max_turns": 8,
		"store": "memory"
	},
	"logging": {"level": "INFO", "json": true}
}


